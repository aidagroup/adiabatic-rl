
"""
FOR EXPERIMENTAL EVALUATION!!
goes into all local subdirs x in ./ and creates a file x.csv. This file will have one header, one data row and 2 cols x_reward and x_length 
for every file in x.
Invocation: python3 condense.py ./results EXP2

This can then be associated with the csv file generated by slurm-exp using the assoc_data.py script in slurm-exp:
python3 ../../slurm-exp/assoc_data.py ../iccp-lf__EXP2_db.csv
You then have one big csv file with all results, can eg be imported into Excel or OOCalc

"""
import sys, os ;
SUFFIX = ".csv"
SEP = ","


if len(sys.argv) != 3:
  print("Directory param + filter param expected!") ;
  sys.exit(0) ;
base_dir,filter_str = sys.argv[1:3] ;

print(base_dir, filter_str) ;
dirs = [os.path.join(base_dir,d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir,d)) and (d != ".") and (d != "..") and (d.find(filter_str) != -1)]
print("found", len(dirs))

for d in dirs:
  header_str = "" ;
  content_str = "" ;
  files = reversed(sorted([f  for f in os.listdir(d) if f.find(SUFFIX) != -1]));
  print("Prcessing", d) ;
  for f in files:
    #print("Opening", os.path.join(d,f)) ;
    content = open(os.path.join(d,f),"r",encoding="utf8").readlines() ;

    data = [[str(f) for f in l.strip().split(" ")] for l in content] ;


    acc_score = 0. ;
    acc_length = 0. ;

    for line in data:
      acc_score += float(line[1]) ;
      acc_length += float(line[2]) ;
    mean_score = acc_score / len(data) ;
    mean_length = acc_length / len(data) ;
    header_str  = header_str + f + "_length" + SEP + f + "_score" + SEP 
    content_str = content_str + "%.02f"%(mean_length)+SEP + "%.02f"%(mean_score)+SEP ;
  out = open(d + ".csv","w") ;
  out.write(header_str+"\n") ;
  out.write(content_str+"\n") ;
  out.close() ;

    

